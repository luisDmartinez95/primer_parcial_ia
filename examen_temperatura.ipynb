{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oamjUd66EHX",
        "outputId": "dea24082-0081-4c3a-86b6-9c8d38e4ebbf"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Acer/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Ruta local al archivo (ajusta la ruta según tu sistema)\n",
        "ruta_archivo = 'C:/Users/Acer/OneDrive/Escritorio/primer_parcial_ia/Temp_Asu20092021.xlsx'\n",
        "\n",
        "# Leer el archivo CSV y crear un DataFrame\n",
        "# Cargar el dataset\n",
        "data = pd.read_csv(\"Temp_Asu20092021.csv\")\n",
        "\n",
        "# Convertir la columna 'Fecha' a tipo datetime\n",
        "data['Fecha'] = pd.to_datetime(data['Fecha'])\n",
        "\n",
        "# Establecer la columna 'Fecha' como índice\n",
        "data.set_index('Fecha', inplace=True)\n",
        "\n",
        "# Filtrar datos desde 2019 en adelante\n",
        "data = data[data.index.year >= 2019]\n",
        "\n",
        "# Eliminar filas con valores faltantes\n",
        "data.dropna(inplace=True)\n",
        "#. Reindexar el DataFrame para tener una frecuencia horaria\n",
        "\n",
        "data = data.resample('H').interpolate()\n",
        "# Resamplear el conjunto de datos a intervalos diarios y calcular la temperatura máxima diaria\n",
        "daily_max_temperatures = data['Temperatura'].resample('D').max()\n",
        "\n",
        "data['Max_Temperature_Day'] = data.groupby(data.index.date)['Temperatura'].transform('max')\n",
        "# . Calcular el percentil 95 de la temperatura diaria\n",
        "data['Percentil_95'] = data.groupby(data.index.date)['Temperatura'].transform(lambda x: x.quantile(0.95))\n",
        "\n",
        "\n",
        "# ----> EXPLORACIÓN DE CARACTERÍSTICAS <----\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = data.corr()\n",
        "\n",
        "# Visualizar la matriz de correlación con un mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Matriz de Correlación')\n",
        "plt.show()\n",
        "# Objetivo: predecir la temperatura máxima del siguiente día\n",
        "data['NextDay_Temp'] = data['Max_Temperature_Day'].shift(-24)\n",
        "\n",
        "# Eliminar filas con valores faltantes tras el desplazamiento\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Definir características (features) y variable objetivo (target)\n",
        "X = data[['Temperatura']]  # Puedes agregar más características según sea necesario\n",
        "y = data['NextDay_Temp']\n",
        "\n",
        "# Normalizar las características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y validación\n",
        "train_indices = (data.index.year <= 2020)\n",
        "val_indices = (data.index.year == 2021)\n",
        "\n",
        "X_train, X_val = X_scaled[train_indices], X_scaled[val_indices]\n",
        "y_train, y_val = y[train_indices], y[val_indices]\n",
        "\n",
        "# Definir el modelo de regresión Ridge\n",
        "ridge = Ridge()\n",
        "\n",
        "# Definir la cuadrícula de parámetros para GridSearch\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]  # Regularización L2\n",
        "}\n",
        "\n",
        "# Usar GridSearchCV para buscar los mejores hiperparámetros\n",
        "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(\"Mejores hiperparámetros:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Evaluar el modelo con los mejores hiperparámetros en el conjunto de validación\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_val)\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "(f\"Mean Squared Error en validación: {mse}\")\n",
        "#  Mostrar las primeras filas del DataFrame\n",
        "# ----> INICIO DEL CÁLCULO DE MÉTRICAS DE EVALUACIÓN <----\n",
        "\n",
        "\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(f'MSE: {mse}')\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'MAE: {mae}')\n",
        "print(f'R²: {r2}')\n",
        "\n",
        "# ----> FIN DEL CÁLCULO DE MÉTRICAS DE EVALUACIÓN <----\n",
        "# ----> INICIO DEL CÓDIGO DE GRIDSEARCHCV <---- \n",
        "\n",
        "# Definir el modelo de regresión Ridge\n",
        "model = Ridge()\n",
        "\n",
        "# Definir la cuadrícula de hiperparámetros\n",
        "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Realizar Grid Search con validación cruzada de 5 pliegues\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obtener los mejores hiperparámetros\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Mejores hiperparámetros: {best_params}')\n",
        "\n",
        "# Obtener el mejor modelo\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# ----> FIN DEL CÓDIGO DE GRIDSEARCHCV <----\n",
        "\n",
        "# ----> FIN DE LA CONSTRUCCIÓN Y EVALUACIÓN DEL MODELO FINAL <----\n",
        "\n",
        "print(data.head())\n",
        "# ----> GRÁFICO DE DISPERSIÓN <----\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_val, y_pred) # Asegúrate de usar y_val aquí\n",
        "plt.xlabel('Valor real')\n",
        "plt.ylabel('Predicción')\n",
        "plt.title('Gráfico de dispersión: Valor real vs. Predicción')\n",
        "\n",
        "# Agregar una línea diagonal (para una referencia visual)\n",
        "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red', linestyle='--') \n",
        "\n",
        "plt.show()\n",
        "\n",
        "# ----> FIN DEL GRÁFICO DE DISPERSIÓN <----\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Acer/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
